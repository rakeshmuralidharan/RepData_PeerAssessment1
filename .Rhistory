arrange(x, var1)
arrange(x, desc(var1))
x$var4 = rnorm(5)
x
y = cbind(x, rnorm(5))
y
if(!file.exists("./Data")){dir.create("./Data")}
dir.list()
dir.list
files.list()
file.list()
list.files()
list.dir()
dir.list()
list.dirs()
getwd()
fileUrl = "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv", method = "curl")
install.packages('ggplot2', dep=TRUE, lib=NULL)
library(ggplot2)
library("ggplot2", lib.loc="C:/Program Files/R/R-3.1.1/library")
remove.packages("ggplot2")
library(ggplot2)
install.packages('ggplot2', dep=TRUE, lib=NULL)
library(ggplot2)
library(ggplot2)
install.packages('ggplot2', dep=TRUE, lib=NULL)
install.packages('ggplot2', dep=TRUE)
library(ggplot2)
sessinInfo()
restData = read.csv("./data/Restaurants.csv")
head(restData)
str(restData)
summary(restData)
quantile(restdata$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, probs = c(0.5, 075, 0.9))
quantile(restData$councilDistrict, probs = c(0.5, 0.75, 0.9))
table(restData$zipCode, useNA = "inAny")
table(restData$zipCode, useNA = "ifAny")
table(restData$zipCode, useNA = "ifany")
?table
??useNA
table(restData$councilDistrict, restData$zipCode)
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
str(DF)
xt = xtabs(Freq~Gender+Admit, data=DF)
xt
str(warpbreaks)
warpbreaks$replicate = rep(1:9, len = 54)
str(warpbreaks)
xt = xtabs(breaks~., data = warpbreaks)
xt
ftables(xt)
ftable(xt)
fakeData = rnorm(1e5)
str(fakeData)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
head(restData)
s1 = seq(1:10, by = 2)
s1 = seq(1,10, by = 2)
s1
s2 = seq(1,10, length = 3)
s2
x = c(1,3,8,25,100)
seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
head(restData$nearMe)
table(restData$nearMe)
R.version.string
install.packages("swirl")
library(swirl)
ls()
rm(list = ls())
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(-(X:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparision
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size/2^20)
mutate(cran3, size_mb = size/2^20, size_gb = size_mb/ 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(.cran, package)
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(pack_sum, desc(count))
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
swirl()
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
student2
students2
res = gather(students2, sex_class, count, -grade)
res <-  gather(students2, sex_class, count, -grade)
res
?separate()
?separate
separate(data=res, col=sex_class, into = c("sex", "class"))
submit()
submit()
submit()
submit()
student3
students3
submit()
?spread
submit()
extract_numeric("class5")
?mutate
submit()
submit()
student4
students4
submit()
submit()
submit()
submit()
submit()
passed
failed
passed = mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?rbind_list
rbind_list(passed, failed)
sat
?separate
submit()
submit()
reset()
sat
?gather
submit
submit()
submit()
submit()
?contains
??contains
?select
sat
submit()
submit()
submit()
?mutate
?group_by
submit()
cameraData = read.csv("Baltimore_Fixed_Speed_Cameras.csv")
names(cameraData)
tolower(cameraData)
tolower(names(cameraData))
splitNames = strsplit(names(cameraData), "\\.")
splitNames
testName = "this_is_a_test"
sub("_", "", testName)
gsub("_", "", testName)
grep("Alameda", cameraData$Intersection)
grep("Alameda", cameraData$intersection)
grepl("Alameda", cameraData$intersection)
table(grepl("Alameda", cameraData$intersection))
library(stringr)
nchar("Jeff Leek")
substr("Jeffery Leek", 1,7)
paste("Jeff", "Leek")
paste0("Jeff", "Leek")
str_trim("Jeff    ")
getwd()
acs = read.csv("getdata-data-ss06pid")
acs = read.csv("getdata-data-ss06pid.csv")
str(acs)
names(acs)
head(acs$WGTP)
head(acs$wgtp)
splitNames = strsplit(names(acs), "wgtp")
splitNames
splitNames[125]
splitNames[123]
splitNames[123,]
splitNames[123]
splitNames = strsplit(names(acs), "\\wgtp")
splitNames[123]
splitNames[,123]
splitNames[123]
head(acs$WGTP)
str(acs$WGTP)
str(acs)
cameraData
acs = read.csv("getdata-data-ss06hid.csv")
str(acs)
strsplit(names(acs), "wgtp")
strsplit(names(acs), "wgtp")[123]
strsplit(names(acs), "wgtp")[[123]]
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
str(sampleTimes)
head(sampleTimes)
class(sampleTimes)
year(sampleTimes)
years(sampleTimes)
head(format(sampleTimes, %Y))
format(sampleTimes, "%Y")
head(format(sampleTimes, "%Y"))
head(sampleTimes)
class(format(sampleTimes, "%Y"))
sampleTimes[format(sampleTimes, "%Y") == "2012",]
sampleTimes[format(sampleTimes, "%Y") == "2012"]
length(sampleTimes[format(sampleTimes, "%Y") == "2012"])
wday(sampleTimes)
library(lubridate)
install.packages("lubridate")
library(lubridate)
wday(sampleTimes)
wday(sampleTimes, label=TRUE)
head(wday(sampleTimes, label=TRUE))
class(wday(sampleTimes, label=TRUE))
length(sampleTimes[format(sampleTimes, "%Y") == "2012" & as.character(wday(sampleTimes, label=TRUE)) == "Mon"])
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day = today()
this_day <- today()
this_day
year(this_dat)
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = hours(now()), minutes = min(now()), seconds = sec(now()))
now()
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
?now
now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart = update(depart, hours = 17, minutes = 34, seconds = 0)
depart = update(depart, hours = 17, minutes = 34)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive, tzone = attr(last_time, "Asia/Singapore"))
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
set.seed(1234)
par(mar = c(0,0,0,0))
x = rnorm(12, mean = rep(1:3, each = 4), sd = 0.4
)
y = rnorm(12, mean = rep(c(1,2,1), each = 4), sd = 0.2)
plot(x,y, col = "blue", pch = 19, cex = 2)
text(x+0.05, y+0.05, labels = as.character(1:12))
dataFrame = data.frame(x = x, y = y)
dataFrame
dist(dataFrame)
distxy = dist(dataFrame)
hClusturing = hclust(distxy)
plot(hClusturing)
getwd()
ls
ls()
rm(list = ls())
ls()
getwd
get.files()
dir.files()
files.dir()
list.files()
sms_data = read.csv("./PacktPub/sms_spam.csv")
str(sms_data)
sms_data = read.csv("./PacktPub/sms_spam.csv", stringsAsFactors = FALSE)
str(sms_data)
sms_raw = read.csv("./PacktPub/sms_spam.csv", stringsAsFactors = FALSE)
sms_raw$type = factor(sms_raw$type)
str(sms_raw)
table(sms_raw$type)
install.packages("tm")
library(tm)
sms_corpus = Corpus(VetorSource(sms_raw$text))
sms_corpus = Corpus(VectorSource(sms_raw$text))
str(sms_corpus)
class(sms_corpus)
print(vignette("tm"))
print(sms_corpus)
inspect(sms_corpus[1])
inspect(sms_corpus[1:3])
corpus_clean = tm_map(sms_corpus, tolower)
inspect(corpus_clean[1:3])
corpus_clean = tm_map(corpus_clean, removeNumbers)
inspect(corpus_clean[1:3])
stopwords()
corpus_clean = tm_map(corpus_clean, removeWords, stopwords())
inspect(corpus_clean[1:3])
corpus_clean = tm_map(corpus_clean, removePunctuation)
inspect(corpus_clean[1:3])
corpus_clean = tm_map(corpus_clean, stripWhitespace)
inspect(corpus_clean[1:3])
sms_dtm = DocumentTermMatrix(corpus_clean)
corpus_clean1 = tm_map(corpus_clean, PlainTextDocument)
inspect(corpus_clean1[1:3])
sms_dtm = DocumentTermMatrix(corpus_clean1)
class(sms_dtm)
sms_dtm
sms_dtm()
str(sms_dtm)
dim(sms_dtm)
ls()
sms_raw = read.csv("./PacktPub/sms_spam.csv", stringsAsFactors = FALSE)
sms_raw$type = factor(sms_raw$type)
install.packages("tm")
library(tm)
sms_corpus = Corpus(VectorSource(sms_raw$text))
corpus_clean = tm_map(sms_corpus, tolower)
corpus_clean = tm_map(corpus_clean, removeNumbers)
corpus_clean = tm_map(corpus_clean, removeWords, stopwords())
corpus_clean = tm_map(corpus_clean, removePunctuation)
corpus_clean = tm_map(corpus_clean, stripWhitespace)
corpus_clean1 = tm_map(corpus_clean, PlainTextDocument)
sms_dtm = DocumentTermMatrix(corpus_clean1)
sms_raw_train = sms_raw[1:4169,]
sms_raw_test = sms_raw[4170:5559,]
sms_dtm_train = sms_dtm[1:4169,]
sms_dtm_test = sms_dtm[4170:5559,]
sms_corpus_train = corpus_clean1[1:4169,]
sms_corpus_test = corpus_clean1[4170:5559,]
sms_corpus_train = corpus_clean1[1:4169]
sms_corpus_test = corpus_clean1[4170:5559]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_raw_train, min.freq = 40, randon.order = FALSE)
wordcloud(sms_corpus_train, min.freq = 40, randon.order = FALSE)
findFreqTerms(sms_dtm_train, 5)
sms_dict = Dictionary(findFreqTerms(sms_dtm_train, 5))
?Dictionary
class(findFreqTerms(sms_dtm_train, 5)
)
sms_dict = findFreqTerms(sms_dtm_train, 5)
length(sms_dict)
class(sms_dict)
sms_train = DocumentTermMatrix(sms_corpus_train, list(dictionary =
sms_dict))
class(sms_train)
inspect(sms_train, 1:3)
inspect(sms_train[1:3]
)
sms_test = DocumentTermMatrix(sms_corpus_test, list(dictionary =
sms_dict))
inspect(sms_train)
inspect(sms_train[1:3,])
inspect(sms_train[1:3])
inspect(sms_dtm_train[1:3])
inspect(sms_dtm_train[3])
inspect(sms_dtm_train[1,])
convert_counts = function(x) {
x = ifelse(x > 0, 1, 0)
x = factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
sms_train = apply(sms_train, MARGIN = 2, convert_counts)
class(sms_train)
dim(sms_train)
sms_test = apply(sms_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier = naiveBayes(sms_train, sms_raw_train$type)
sms_test_pred = predict(sms_classifier, sms_test)
library(gmodels)
install.packages("gmodels")
library(gmodels)
CrossTable(sms_test_pred, sms_test_raw$type, prop.chisq = FALSE,
prop.t = FALSE, dnn = c('predicted', 'Actual'))
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE,
prop.t = FALSE, dnn = c('predicted', 'Actual'))
sms_classifier2 = naiveBayes(sms_train, sms_raw_train$type, laplace = 1)
sms_test_pred = predict(sms_classifier, sms_test)
sms_test_pred2 = predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_raw_test$type, prop.chisq = FALSE,
prop.t = FALSE, dnn = c('predicted', 'actual'))
getwd()
setwd("C:/Users/juliuscezar/Desktop/Coursera/RepResearch")
clear
head(activity)
ls
ls()
activity
activity = read.csv("activity.csv")
head(activity)
table(activity$steps)
head(activity, is.na = FALSE)
head(activity, is.na = TRUE)
str(activity)
mean(activity$steps)
mean(activity$steps, rm.na = TRUE)
mean(activity$steps, na.rm = TRUE)
table(activity$date)
table(activity$date, sum(activity$steps))
unique(activity$date)
length(unique(activity$date))
sum(activity$steps, na.rm = TURE)
sum(activity$steps, na.rm = TRUE)
sum(activity$steps)
sum(activity$steps, na.rm = TRUE)
sum(activity$steps, na.rm = TRUE)/length(unique(activity$date))
570608/61
sqldf(select * from activity)
sqldf("select * from activity")
library(sqldf)
install.packages("sqldf")
library(sqldf)
